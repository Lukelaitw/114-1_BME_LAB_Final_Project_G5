# CTNet EEG åˆ†é¡å™¨

> **èªè¨€ç‰ˆæœ¬é¸æ“‡ / Language Selection**
> 
> - ğŸ‡¹ğŸ‡¼ [ç¹é«”ä¸­æ–‡ (Traditional Chinese)](README.md) â† ç•¶å‰ç‰ˆæœ¬
> - ğŸ‡ºğŸ‡¸ [English](README_EN.md)

## å°ˆæ¡ˆæ¦‚è¿°

æœ¬æ¨¡çµ„å¯¦ç¾äº†åŸºæ–¼ CTNet (Convolution-Transformer Network) çš„ EEG ä¿¡è™Ÿåˆ†é¡ç³»çµ±ï¼Œç”¨æ–¼å€åˆ†ã€Œå°ˆæ³¨ã€èˆ‡ã€Œæ”¾é¬†ã€å…©ç¨®è…¦é›»ç‹€æ…‹ã€‚æ¡ç”¨ Leave-One-Subject-Out (LOSO) äº¤å‰é©—è­‰æ–¹æ³•ï¼Œåœ¨ 35 ä½å—è©¦è€…çš„æ•¸æ“šé›†ä¸Šé€²è¡Œè¨“ç·´èˆ‡è©•ä¼°ã€‚

## æ¨¡å‹æ¶æ§‹

CTNet çµåˆäº†å·ç©ç¥ç¶“ç¶²çµ¡ï¼ˆCNNï¼‰å’Œ Transformer çš„å„ªå‹¢ï¼Œç”¨æ–¼è™•ç† EEG æ™‚åºæ•¸æ“šï¼š

![CTNet æ¶æ§‹](architecture.png)

### æ¶æ§‹ç‰¹é»

1. **Patch Embedding CNN**ï¼šå°‡åŸå§‹ EEG ä¿¡è™Ÿè½‰æ›ç‚ºé©åˆ Transformer è™•ç†çš„ patch embeddings
   - æ™‚åŸŸå·ç©ï¼ˆTemporal Convolutionï¼‰
   - æ·±åº¦å¯åˆ†é›¢å·ç©ï¼ˆDepth-wise Convolutionï¼‰
   - ç©ºé–“å·ç©ï¼ˆSpatial Convolutionï¼‰
   - å¹³å‡æ± åŒ–ï¼ˆAverage Poolingï¼‰

2. **Transformer Encoder**ï¼šæ•æ‰é•·è·é›¢æ™‚åºä¾è³´é—œä¿‚
   - å¤šé ­è‡ªæ³¨æ„åŠ›æ©Ÿåˆ¶ï¼ˆMulti-Head Self-Attentionï¼‰
   - å‰é¥‹ç¥ç¶“ç¶²çµ¡ï¼ˆFeed-Forward Networkï¼‰
   - å±¤æ­¸ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰

3. **åˆ†é¡é ­**ï¼šæœ€çµ‚çš„åˆ†é¡å±¤

### æ¨¡å‹é…ç½®

æœ¬å°ˆæ¡ˆåŒ…å«å…©å€‹ä¸»è¦æ¨¡å‹é…ç½®ï¼š

- **Loso_C_heads_2_depth_6_0**ï¼š6 å±¤ Transformer encoderï¼Œ2 å€‹æ³¨æ„åŠ›é ­
- **Loso_C_heads_2_depth_8_0**ï¼š8 å±¤ Transformer encoderï¼Œ2 å€‹æ³¨æ„åŠ›é ­ï¼ˆæ¨è–¦ç”¨æ–¼å³æ™‚æ¨ç†ï¼‰

## æ•¸æ“šé›†

### æ•¸æ“šæ ¼å¼

- **æ•¸æ“šé›†è·¯å¾‘**ï¼š`bci_dataset_113-2/`
- **å—è©¦è€…æ•¸é‡**ï¼š35 ä½ï¼ˆS01-S35ï¼‰
- **æ•¸æ“šçµæ§‹**ï¼š
  ```
  bci_dataset_113-2/
  â”œâ”€â”€ S01/
  â”‚   â”œâ”€â”€ 1.txt  # é¡åˆ¥1ï¼šå°ˆæ³¨
  â”‚   â””â”€â”€ 2.txt  # é¡åˆ¥2ï¼šæ”¾é¬†
  â”œâ”€â”€ S02/
  â”‚   â”œâ”€â”€ 1.txt
  â”‚   â””â”€â”€ 2.txt
  â””â”€â”€ ...
  ```

### æ•¸æ“šè¦æ ¼

- **é€šé“æ•¸**ï¼š1 é€šé“ï¼ˆå–®é€šé“ EEGï¼‰
- **æ¡æ¨£ç‡**ï¼š500 Hz
- **çª—å£å¤§å°**ï¼š1000 æ¨£æœ¬ï¼ˆç´„ 2 ç§’ï¼‰
- **é¡åˆ¥**ï¼š2 é¡ï¼ˆå°ˆæ³¨ vs æ”¾é¬†ï¼‰

## è¨“ç·´

### è¨“ç·´æ–¹æ³•

æ¡ç”¨ **Leave-One-Subject-Out (LOSO)** äº¤å‰é©—è­‰ï¼š
- æ¯æ¬¡è¨“ç·´æ™‚ï¼Œä½¿ç”¨ 34 ä½å—è©¦è€…çš„æ•¸æ“šä½œç‚ºè¨“ç·´é›†
- å‰©é¤˜ 1 ä½å—è©¦è€…çš„æ•¸æ“šä½œç‚ºæ¸¬è©¦é›†
- é‡è¤‡ 35 æ¬¡ï¼Œæ¯ä½å—è©¦è€…è¼ªæµä½œç‚ºæ¸¬è©¦é›†
- æœ€çµ‚å¾—åˆ° 35 å€‹æ¨¡å‹ï¼ˆ`model_1.pth` åˆ° `model_35.pth`ï¼‰

### è¨“ç·´åƒæ•¸

é è¨­é…ç½®ï¼ˆè¦‹ `loso.py`ï¼‰ï¼š

```python
EPOCHS = 1000              # è¨“ç·´è¼ªæ•¸
HEADS = 2                  # Transformer æ³¨æ„åŠ›é ­æ•¸
EMB_DIM = 16               # åµŒå…¥ç¶­åº¦
DEPTH = 8                  # Transformer encoder å±¤æ•¸
BATCH_SIZE = 512           # æ‰¹æ¬¡å¤§å°
LEARNING_RATE = 0.001      # å­¸ç¿’ç‡
N_AUG = 3                  # æ•¸æ“šå¢å¼·å€æ•¸
N_SEG = 50                 # åˆ†æ®µæ¬¡æ•¸ï¼ˆS&R æ•¸æ“šå¢å¼·ï¼‰
VALIDATE_RATIO = 0.1       # é©—è­‰é›†æ¯”ä¾‹
DROPOUT_RATE = 0.25        # Dropout ç‡ï¼ˆLOSO æ¨¡å¼ï¼‰
```

### æ•¸æ“šå¢å¼·

ä½¿ç”¨ **Segmentation and Reconstruction (S&R)** æ–¹æ³•ï¼š
- å°‡åŸå§‹åºåˆ—åˆ†æ®µä¸¦é‡çµ„
- å¢åŠ è¨“ç·´æ•¸æ“šçš„å¤šæ¨£æ€§
- æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›

### åŸ·è¡Œè¨“ç·´

```bash
cd Classifier
python loso.py
```

è¨“ç·´éç¨‹æœƒï¼š
1. è‡ªå‹•é€²è¡Œ LOSO äº¤å‰é©—è­‰
2. ä¿å­˜æ¯å€‹å—è©¦è€…çš„æœ€ä½³æ¨¡å‹
3. ç”Ÿæˆçµæœ Excel æ–‡ä»¶ï¼š
   - `result_metric.xlsx`ï¼šå„å—è©¦è€…çš„è©•ä¼°æŒ‡æ¨™
   - `process_train.xlsx`ï¼šè¨“ç·´éç¨‹è¨˜éŒ„
   - `pred_true.xlsx`ï¼šé æ¸¬çµæœèˆ‡çœŸå¯¦æ¨™ç±¤
4. è‡ªå‹•ç¹ªè£½çµæœåœ–è¡¨

## æ¨ç†

### å–®æ¨¡å‹æ¨ç†

ä½¿ç”¨ `CTNetInference` é¡é€²è¡Œå–®å€‹æ¨¡å‹çš„æ¨ç†ï¼š

```python
from inference import CTNetInference

# åˆå§‹åŒ–æ¨ç†å™¨
inferencer = CTNetInference(
    model_path="Loso_C_heads_2_depth_8_0/model_1.pth",
    dataset_type='C',
    heads=2, emb_size=16, depth=8,
    eeg1_f1=8, eeg1_kernel_size=64, eeg1_D=2,
    eeg1_pooling_size1=8, eeg1_pooling_size2=8,
    eeg1_dropout_rate=0.25, flatten_eeg1=240
)

# å¾ txt æ–‡ä»¶æ¨ç†
prediction, probability = inferencer.predict_from_txt("bci_dataset_113-2/S01/1.txt")
print(f"é æ¸¬é¡åˆ¥: {prediction}, æ¦‚ç‡: {probability}")
```

### Ensemble æ¨ç†ï¼ˆæ¨è–¦ï¼‰

ä½¿ç”¨ `CTNetEnsembleInference` é¡é€²è¡Œå¤šæ¨¡å‹é›†æˆæ¨ç†ï¼Œé€šå¸¸èƒ½æä¾›æ›´ç©©å®šå’Œæº–ç¢ºçš„çµæœï¼š

```python
from inference import CTNetEnsembleInference

# åˆå§‹åŒ– Ensemble æ¨ç†å™¨ï¼ˆè‡ªå‹•è¼‰å…¥æ‰€æœ‰æ¨¡å‹ï¼‰
inferencer = CTNetEnsembleInference(
    model_dir="Loso_C_heads_2_depth_8_0",
    dataset_type='C',
    heads=2, emb_size=16, depth=8,
    eeg1_f1=8, eeg1_kernel_size=64, eeg1_D=2,
    eeg1_pooling_size1=8, eeg1_pooling_size2=8,
    eeg1_dropout_rate=0.25, flatten_eeg1=240
)

# å¾ txt æ–‡ä»¶æ¨ç†ï¼ˆä½¿ç”¨æ‰€æœ‰æ¨¡å‹çš„å¹³å‡é æ¸¬ï¼‰
prediction, probability = inferencer.predict_from_txt("bci_dataset_113-2/S01/1.txt")
print(f"é æ¸¬é¡åˆ¥: {prediction}, æ¦‚ç‡: {probability}")
```

### å¯¦æ™‚æ¨ç†

ä½¿ç”¨æ»‘å‹•çª—å£é€²è¡Œé€£çºŒæ•¸æ“šæµçš„å¯¦æ™‚æ¨ç†ï¼š

```python
import numpy as np
from inference import CTNetEnsembleInference

# åˆå§‹åŒ–æ¨ç†å™¨
inferencer = CTNetEnsembleInference(
    model_dir="Loso_C_heads_2_depth_8_0",
    dataset_type='C',
    heads=2, emb_size=16, depth=8,
    eeg1_f1=8, eeg1_kernel_size=64, eeg1_D=2,
    eeg1_pooling_size1=8, eeg1_pooling_size2=8,
    eeg1_dropout_rate=0.25, flatten_eeg1=240
)

# å®šç¾©æ•¸æ“šæµç”Ÿæˆå™¨ï¼ˆæ¨¡æ“¬å¯¦æ™‚æ¥æ”¶ï¼‰
def data_stream_generator(data, chunk_size=200):
    for i in range(0, len(data), chunk_size):
        yield data[i:i+chunk_size]

# è®€å–æ•¸æ“š
data = np.loadtxt("bci_dataset_113-2/S01/1.txt", dtype=np.float32)

# å¯¦æ™‚æ¨ç†
class_names = ['æ”¾é¬†', 'å°ˆæ³¨']
for result in inferencer.predict_realtime(
    data_stream_generator(data, chunk_size=200),
    window_size=1000,      # çª—å£å¤§å°ï¼ˆ2ç§’ï¼‰
    stride=500,            # æ»‘å‹•æ­¥é•·ï¼ˆ1ç§’ï¼‰
    smoothing_window=5     # å¹³æ»‘çª—å£
):
    pred = result['prediction']
    prob = result['probability']
    print(f"é æ¸¬: {class_names[pred]}, æ¦‚ç‡: {prob}")
```

### å‘½ä»¤è¡Œæ¨ç†

```bash
# å¾ txt æ–‡ä»¶æ¨ç†
python inference.py \
    --model_path Loso_C_heads_2_depth_8_0/model_1.pth \
    --txt_file bci_dataset_113-2/S01/1.txt \
    --dataset_type C \
    --heads 2 --emb_size 16 --depth 8

# æ‰¹é‡æ¨ç†ï¼ˆå¾ç›®éŒ„ï¼‰
python inference.py \
    --model_path Loso_C_heads_2_depth_8_0/model_1.pth \
    --data_dir ./test_data/ \
    --dataset_type C
```

### æ¨ç†ç¯„ä¾‹

æŸ¥çœ‹ `inference_example.py` ç²å–æ›´å¤šä½¿ç”¨ç¯„ä¾‹ï¼š

```bash
python inference_example.py
```

## çµæœå±•ç¤º

### åˆ†é¡æ€§èƒ½

#### æœ€ä½³çµæœ

![æœ€ä½³åˆ†é¡çµæœ](bci_results_best.png)

#### ä¸åŒè¨“ç·´é…ç½®çš„çµæœæ¯”è¼ƒ

**Base æ¨¡å‹ï¼ˆ100 epochsï¼‰**

![Base æ¨¡å‹çµæœ](bci_results_data_base_e100.png)

**Extended æ¨¡å‹ï¼ˆ1000 epochsï¼‰**

![Extended æ¨¡å‹çµæœ](bci_results_data_e1000.png)

### è©•ä¼°æŒ‡æ¨™

æ¨¡å‹è©•ä¼°ä½¿ç”¨ä»¥ä¸‹æŒ‡æ¨™ï¼š
- **æº–ç¢ºç‡ï¼ˆAccuracyï¼‰**
- **ç²¾ç¢ºç‡ï¼ˆPrecisionï¼‰**
- **å¬å›ç‡ï¼ˆRecallï¼‰**
- **F1 åˆ†æ•¸ï¼ˆF1-Scoreï¼‰**
- **Cohen's Kappa**

çµæœä¿å­˜åœ¨ `result_metric.xlsx` ä¸­ï¼ŒåŒ…å«æ¯ä½å—è©¦è€…çš„è©³ç´°æŒ‡æ¨™ã€‚

### çµæœè¦–è¦ºåŒ–

ä½¿ç”¨ `plot_figures/` ç›®éŒ„ä¸‹çš„è…³æœ¬ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨ï¼š

- `confusion_matrix.py`ï¼šæ··æ·†çŸ©é™£
- `depth.py`ï¼šä¸åŒæ·±åº¦é…ç½®çš„æ¯”è¼ƒ
- `heads.py`ï¼šä¸åŒæ³¨æ„åŠ›é ­æ•¸çš„æ¯”è¼ƒ
- `length.py`ï¼šä¸åŒçª—å£é•·åº¦çš„æ¯”è¼ƒ

## æ–‡ä»¶çµæ§‹

```
Classifier/
â”œâ”€â”€ bci_dataset_113-2/          # æ•¸æ“šé›†ï¼ˆ35 ä½å—è©¦è€…ï¼‰
â”‚   â”œâ”€â”€ S01/
â”‚   â”‚   â”œâ”€â”€ 1.txt               # å°ˆæ³¨ç‹€æ…‹æ•¸æ“š
â”‚   â”‚   â””â”€â”€ 2.txt               # æ”¾é¬†ç‹€æ…‹æ•¸æ“š
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Loso_C_heads_2_depth_6_0/    # 6å±¤æ¨¡å‹çµæœ
â”‚   â”œâ”€â”€ model_1.pth ~ model_35.pth
â”‚   â”œâ”€â”€ result_metric.xlsx
â”‚   â”œâ”€â”€ process_train.xlsx
â”‚   â””â”€â”€ pred_true.xlsx
â”œâ”€â”€ Loso_C_heads_2_depth_8_0/   # 8å±¤æ¨¡å‹çµæœï¼ˆæ¨è–¦ï¼‰
â”‚   â”œâ”€â”€ model_1.pth ~ model_35.pth
â”‚   â”œâ”€â”€ result_metric.xlsx
â”‚   â”œâ”€â”€ process_train.xlsx
â”‚   â””â”€â”€ pred_true.xlsx
â”œâ”€â”€ loso.py                     # è¨“ç·´è…³æœ¬
â”œâ”€â”€ inference.py                # æ¨ç†è…³æœ¬
â”œâ”€â”€ inference_example.py        # æ¨ç†ç¯„ä¾‹
â”œâ”€â”€ utils.py                    # å·¥å…·å‡½æ•¸
â”œâ”€â”€ plot_figures/              # çµæœè¦–è¦ºåŒ–è…³æœ¬
â”‚   â”œâ”€â”€ confusion_matrix.py
â”‚   â”œâ”€â”€ depth.py
â”‚   â”œâ”€â”€ heads.py
â”‚   â””â”€â”€ length.py
â”œâ”€â”€ architecture.png            # æ¨¡å‹æ¶æ§‹åœ–
â”œâ”€â”€ bci_results_best.png        # æœ€ä½³çµæœåœ–
â”œâ”€â”€ bci_results_data_base_e100.png
â””â”€â”€ bci_results_data_e1000.png
```

## ä¾è³´å¥—ä»¶

```bash
pip install torch torchvision numpy pandas matplotlib seaborn scikit-learn einops openpyxl
```

## ä½¿ç”¨å»ºè­°

1. **è¨“ç·´éšæ®µ**ï¼š
   - ä½¿ç”¨ `loso.py` é€²è¡Œ LOSO äº¤å‰é©—è­‰è¨“ç·´
   - æ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´ `batch_size`
   - å¯èª¿æ•´ `N_AUG` å’Œ `N_SEG` ä¾†æ§åˆ¶æ•¸æ“šå¢å¼·å¼·åº¦

2. **æ¨ç†éšæ®µ**ï¼š
   - **æ¨è–¦ä½¿ç”¨ Ensemble æ¨ç†**ï¼ˆ`CTNetEnsembleInference`ï¼‰ä»¥ç²å¾—æ›´å¥½çš„ç©©å®šæ€§
   - å°æ–¼å³æ™‚æ‡‰ç”¨ï¼Œä½¿ç”¨ `predict_realtime()` æ–¹æ³•
   - èª¿æ•´ `smoothing_window` åƒæ•¸ä¾†å¹³è¡¡éŸ¿æ‡‰é€Ÿåº¦å’Œç©©å®šæ€§

3. **æ¨¡å‹é¸æ“‡**ï¼š
   - 8 å±¤æ¨¡å‹ï¼ˆ`Loso_C_heads_2_depth_8_0`ï¼‰é€šå¸¸è¡¨ç¾æ›´å¥½ï¼Œæ¨è–¦ç”¨æ–¼å³æ™‚æ¨ç†
   - 6 å±¤æ¨¡å‹ï¼ˆ`Loso_C_heads_2_depth_6_0`ï¼‰è¨ˆç®—é‡è¼ƒå°ï¼Œé©åˆè³‡æºå—é™çš„ç’°å¢ƒ

## å¼•ç”¨

æœ¬å°ˆæ¡ˆåŸºæ–¼ä»¥ä¸‹è«–æ–‡å¯¦ç¾ï¼š

```
Zhao, W., Jiang, X., Zhang, B. et al. CTNet: a convolutional transformer network 
for EEG-based motor imagery classification. Sci Rep 14, 20237 (2024). 
https://doi.org/10.1038/s41598-024-71118-7
```

## æ³¨æ„äº‹é …

1. **CUDA è¨­ç½®**ï¼šç¢ºä¿å·²æ­£ç¢ºé…ç½® CUDA ç’°å¢ƒï¼Œæ¨¡å‹è¨“ç·´å’Œæ¨ç†éœ€è¦ GPU æ”¯æ´
2. **æ•¸æ“šæ ¼å¼**ï¼šç¢ºä¿è¼¸å…¥æ•¸æ“šæ ¼å¼ç¬¦åˆé æœŸï¼ˆå–®é€šé“ï¼Œ500 Hz æ¡æ¨£ç‡ï¼‰
3. **æ¨¡å‹è·¯å¾‘**ï¼šæ¨ç†æ™‚ç¢ºä¿æ¨¡å‹æ–‡ä»¶è·¯å¾‘æ­£ç¢º
4. **è¨˜æ†¶é«”ç®¡ç†**ï¼šEnsemble æ¨ç†æœƒè¼‰å…¥å¤šå€‹æ¨¡å‹ï¼Œæ³¨æ„ GPU è¨˜æ†¶é«”ä½¿ç”¨

## æ•…éšœæ’é™¤

### æ¨¡å‹è¼‰å…¥å¤±æ•—

- ç¢ºèªæ¨¡å‹æ–‡ä»¶è·¯å¾‘æ­£ç¢º
- æª¢æŸ¥æ¨¡å‹åƒæ•¸é…ç½®æ˜¯å¦èˆ‡è¨“ç·´æ™‚ä¸€è‡´

### CUDA è¨˜æ†¶é«”ä¸è¶³

- æ¸›å° `batch_size`
- ä½¿ç”¨å–®æ¨¡å‹æ¨ç†è€Œé Ensemble
- æ¸›å°‘ `smoothing_window` å¤§å°

### æ¨ç†çµæœä¸ç©©å®š

- å¢åŠ  `smoothing_window` åƒæ•¸
- ä½¿ç”¨ Ensemble æ¨ç†è€Œéå–®æ¨¡å‹
- æª¢æŸ¥è¼¸å…¥æ•¸æ“šè³ªé‡
