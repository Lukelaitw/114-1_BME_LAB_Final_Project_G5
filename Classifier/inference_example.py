"""
CTNetæ¨ç†ä½¿ç”¨ç¤ºä¾‹

é€™å€‹æ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨inference.pyé€²è¡Œæ¨ç†çš„å¹¾ç¨®æ–¹å¼

é‡è¦æç¤ºï¼š
- å°æ–¼LOSOäº¤å‰é©—è­‰ï¼Œæ‡‰è©²ä½¿ç”¨ CTNetEnsembleInference ä¾†åŠ è¼‰æ‰€æœ‰æ¨¡å‹ä¸¦é€²è¡Œå¹³å‡é æ¸¬
- å–®å€‹æ¨¡å‹æ¨ç†ï¼ˆCTNetInferenceï¼‰åªé©ç”¨æ–¼å–®å€‹å—è©¦è€…çš„æ¨¡å‹
- Ensembleæ–¹æ³•é€šå¸¸èƒ½æä¾›æ›´ç©©å®šå’Œæº–ç¢ºçš„é æ¸¬çµæœ
"""

import numpy as np
from inference import CTNetInference, CTNetEnsembleInference


def example_realtime_classification():
    """å¯¦æ™‚åˆ†é¡åˆ†æç¤ºä¾‹ - ä½¿ç”¨æ»‘å‹•çª—å£è™•ç†é€£çºŒæ•¸æ“šæµ"""
    print("\n" + "=" * 50)
    print("ç¤ºä¾‹4: å¯¦æ™‚åˆ†é¡åˆ†æï¼ˆæ»‘å‹•çª—å£ï¼‰")
    print("=" * 50)
    
    # ä½¿ç”¨Ensembleæ¨ç†å™¨
    model_dir = "Loso_C_heads_2_depth_8_0"
    inferencer = CTNetEnsembleInference(
        model_dir=model_dir,
        dataset_type='C',
        heads=2, emb_size=16, depth=8,
        eeg1_f1=8, eeg1_kernel_size=64, eeg1_D=2,
        eeg1_pooling_size1=8, eeg1_pooling_size2=8,
        eeg1_dropout_rate=0.25, flatten_eeg1=240
    )
    
    # æ–¹å¼1: å¾æ–‡ä»¶å¯¦æ™‚è®€å–ï¼ˆæ¨¡æ“¬å¯¦æ™‚æ•¸æ“šæµï¼‰
    print("\n--- æ–¹å¼1: å¾æ–‡ä»¶å¯¦æ™‚è®€å– ---")
    txt_file = "bci_dataset_113-2/S01/2.txt"
    
    try:
        # è®€å–å®Œæ•´æ•¸æ“š
        full_data = np.loadtxt(txt_file, dtype=np.float32)
        print(f"æ•¸æ“šæ–‡ä»¶: {txt_file}")
        print(f"æ•¸æ“šé•·åº¦: {len(full_data)} å€‹æ¨£æœ¬")
        
        # å®šç¾©æ•¸æ“šæµç”Ÿæˆå™¨ï¼ˆæ¨¡æ“¬å¯¦æ™‚æ¥æ”¶æ•¸æ“šï¼‰
        def data_stream_generator(data, chunk_size=200):
            """æ¨¡æ“¬å¯¦æ™‚æ•¸æ“šæµï¼Œæ¯æ¬¡è¿”å›ä¸€å°å¡Šæ•¸æ“š"""
            for i in range(0, len(data), chunk_size):
                yield data[i:i+chunk_size]
        
        # å®šç¾©å›èª¿å‡½æ•¸ï¼ˆæ¯æ¬¡é æ¸¬å¾Œèª¿ç”¨ï¼‰
        class_names = ['æ”¾é¬†', 'å°ˆæ³¨']  # æ ¹æ“šä½ çš„æ•¸æ“šé›†èª¿æ•´
        
        def prediction_callback(result):
            """å¯¦æ™‚é¡¯ç¤ºé æ¸¬çµæœ"""
            pred = result['prediction']
            prob = result['probability']
            window_idx = result['window_idx']
            
            # æ ¼å¼åŒ–è¼¸å‡º
            status = "ğŸŸ¢" if pred == 1 else "ğŸ”µ"
            print(f"çª—å£ {window_idx:4d} | {status} é æ¸¬: {class_names[pred]:4s} | "
                  f"æ¦‚ç‡: [{prob[0]:.3f}, {prob[1]:.3f}] | "
                  f"ç½®ä¿¡åº¦: {max(prob)*100:.1f}%")
        
        # é€²è¡Œå¯¦æ™‚æ¨ç†
        print("\né–‹å§‹å¯¦æ™‚åˆ†æ...")
        print("-" * 70)
        
        results_list = []
        for result in inferencer.predict_realtime(
            data_stream_generator(full_data, chunk_size=200),
            window_size=1000,      # çª—å£å¤§å°
            stride=500,            # æ»‘å‹•æ­¥é•·ï¼ˆè¶Šå°è¶Šå¯¦æ™‚ï¼‰
            smoothing_window=5,     # å¹³æ»‘çª—å£ï¼ˆæ¸›å°‘è·³å‹•ï¼‰
            callback=prediction_callback
        ):
            results_list.append(result)
        
        print("-" * 70)
        print(f"\nåˆ†æå®Œæˆï¼å…±è™•ç† {len(results_list)} å€‹çª—å£")
        
        # çµ±è¨ˆçµæœ
        predictions = [r['prediction'] for r in results_list]
        from collections import Counter
        pred_counts = Counter(predictions)
        print(f"\né æ¸¬çµ±è¨ˆ:")
        for cls_idx, count in pred_counts.items():
            percentage = count / len(predictions) * 100
            print(f"  {class_names[cls_idx]}: {count} æ¬¡ ({percentage:.1f}%)")
        
        return results_list
        
    except FileNotFoundError:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {txt_file}")
        print("è«‹ç¢ºä¿æ•¸æ“šæ–‡ä»¶å­˜åœ¨")
        return None

if __name__ == "__main__":
    # é‹è¡Œç¤ºä¾‹
    print("CTNetæ¨ç†ç¤ºä¾‹\n")
    example_realtime_classification()
    
    print("\n" + "=" * 50)
    print("æ‰€æœ‰ç¤ºä¾‹é‹è¡Œå®Œæˆï¼")
    print("=" * 50)
