{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2cad76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 8, 1, 1000]             512\n",
      "       BatchNorm2d-2           [-1, 8, 1, 1000]              16\n",
      "            Conv2d-3          [-1, 16, 1, 1000]              16\n",
      "       BatchNorm2d-4          [-1, 16, 1, 1000]              32\n",
      "               ELU-5          [-1, 16, 1, 1000]               0\n",
      "         AvgPool2d-6           [-1, 16, 1, 125]               0\n",
      "           Dropout-7           [-1, 16, 1, 125]               0\n",
      "            Conv2d-8           [-1, 16, 1, 125]           4,096\n",
      "       BatchNorm2d-9           [-1, 16, 1, 125]              32\n",
      "              ELU-10           [-1, 16, 1, 125]               0\n",
      "        AvgPool2d-11            [-1, 16, 1, 15]               0\n",
      "          Dropout-12            [-1, 16, 1, 15]               0\n",
      "        Rearrange-13               [-1, 15, 16]               0\n",
      "PatchEmbeddingCNN-14               [-1, 15, 16]               0\n",
      "          Dropout-15               [-1, 15, 16]               0\n",
      "PositioinalEncoding-16               [-1, 15, 16]               0\n",
      "           Linear-17               [-1, 15, 16]             272\n",
      "           Linear-18               [-1, 15, 16]             272\n",
      "           Linear-19               [-1, 15, 16]             272\n",
      "          Dropout-20            [-1, 2, 15, 15]               0\n",
      "           Linear-21               [-1, 15, 16]             272\n",
      "MultiHeadAttention-22               [-1, 15, 16]               0\n",
      "          Dropout-23               [-1, 15, 16]               0\n",
      "        LayerNorm-24               [-1, 15, 16]              32\n",
      "      ResidualAdd-25               [-1, 15, 16]               0\n",
      "           Linear-26               [-1, 15, 64]           1,088\n",
      "             GELU-27               [-1, 15, 64]               0\n",
      "          Dropout-28               [-1, 15, 64]               0\n",
      "           Linear-29               [-1, 15, 16]           1,040\n",
      "          Dropout-30               [-1, 15, 16]               0\n",
      "        LayerNorm-31               [-1, 15, 16]              32\n",
      "      ResidualAdd-32               [-1, 15, 16]               0\n",
      "           Linear-33               [-1, 15, 16]             272\n",
      "           Linear-34               [-1, 15, 16]             272\n",
      "           Linear-35               [-1, 15, 16]             272\n",
      "          Dropout-36            [-1, 2, 15, 15]               0\n",
      "           Linear-37               [-1, 15, 16]             272\n",
      "MultiHeadAttention-38               [-1, 15, 16]               0\n",
      "          Dropout-39               [-1, 15, 16]               0\n",
      "        LayerNorm-40               [-1, 15, 16]              32\n",
      "      ResidualAdd-41               [-1, 15, 16]               0\n",
      "           Linear-42               [-1, 15, 64]           1,088\n",
      "             GELU-43               [-1, 15, 64]               0\n",
      "          Dropout-44               [-1, 15, 64]               0\n",
      "           Linear-45               [-1, 15, 16]           1,040\n",
      "          Dropout-46               [-1, 15, 16]               0\n",
      "        LayerNorm-47               [-1, 15, 16]              32\n",
      "      ResidualAdd-48               [-1, 15, 16]               0\n",
      "           Linear-49               [-1, 15, 16]             272\n",
      "           Linear-50               [-1, 15, 16]             272\n",
      "           Linear-51               [-1, 15, 16]             272\n",
      "          Dropout-52            [-1, 2, 15, 15]               0\n",
      "           Linear-53               [-1, 15, 16]             272\n",
      "MultiHeadAttention-54               [-1, 15, 16]               0\n",
      "          Dropout-55               [-1, 15, 16]               0\n",
      "        LayerNorm-56               [-1, 15, 16]              32\n",
      "      ResidualAdd-57               [-1, 15, 16]               0\n",
      "           Linear-58               [-1, 15, 64]           1,088\n",
      "             GELU-59               [-1, 15, 64]               0\n",
      "          Dropout-60               [-1, 15, 64]               0\n",
      "           Linear-61               [-1, 15, 16]           1,040\n",
      "          Dropout-62               [-1, 15, 16]               0\n",
      "        LayerNorm-63               [-1, 15, 16]              32\n",
      "      ResidualAdd-64               [-1, 15, 16]               0\n",
      "           Linear-65               [-1, 15, 16]             272\n",
      "           Linear-66               [-1, 15, 16]             272\n",
      "           Linear-67               [-1, 15, 16]             272\n",
      "          Dropout-68            [-1, 2, 15, 15]               0\n",
      "           Linear-69               [-1, 15, 16]             272\n",
      "MultiHeadAttention-70               [-1, 15, 16]               0\n",
      "          Dropout-71               [-1, 15, 16]               0\n",
      "        LayerNorm-72               [-1, 15, 16]              32\n",
      "      ResidualAdd-73               [-1, 15, 16]               0\n",
      "           Linear-74               [-1, 15, 64]           1,088\n",
      "             GELU-75               [-1, 15, 64]               0\n",
      "          Dropout-76               [-1, 15, 64]               0\n",
      "           Linear-77               [-1, 15, 16]           1,040\n",
      "          Dropout-78               [-1, 15, 16]               0\n",
      "        LayerNorm-79               [-1, 15, 16]              32\n",
      "      ResidualAdd-80               [-1, 15, 16]               0\n",
      "           Linear-81               [-1, 15, 16]             272\n",
      "           Linear-82               [-1, 15, 16]             272\n",
      "           Linear-83               [-1, 15, 16]             272\n",
      "          Dropout-84            [-1, 2, 15, 15]               0\n",
      "           Linear-85               [-1, 15, 16]             272\n",
      "MultiHeadAttention-86               [-1, 15, 16]               0\n",
      "          Dropout-87               [-1, 15, 16]               0\n",
      "        LayerNorm-88               [-1, 15, 16]              32\n",
      "      ResidualAdd-89               [-1, 15, 16]               0\n",
      "           Linear-90               [-1, 15, 64]           1,088\n",
      "             GELU-91               [-1, 15, 64]               0\n",
      "          Dropout-92               [-1, 15, 64]               0\n",
      "           Linear-93               [-1, 15, 16]           1,040\n",
      "          Dropout-94               [-1, 15, 16]               0\n",
      "        LayerNorm-95               [-1, 15, 16]              32\n",
      "      ResidualAdd-96               [-1, 15, 16]               0\n",
      "           Linear-97               [-1, 15, 16]             272\n",
      "           Linear-98               [-1, 15, 16]             272\n",
      "           Linear-99               [-1, 15, 16]             272\n",
      "         Dropout-100            [-1, 2, 15, 15]               0\n",
      "          Linear-101               [-1, 15, 16]             272\n",
      "MultiHeadAttention-102               [-1, 15, 16]               0\n",
      "         Dropout-103               [-1, 15, 16]               0\n",
      "       LayerNorm-104               [-1, 15, 16]              32\n",
      "     ResidualAdd-105               [-1, 15, 16]               0\n",
      "          Linear-106               [-1, 15, 64]           1,088\n",
      "            GELU-107               [-1, 15, 64]               0\n",
      "         Dropout-108               [-1, 15, 64]               0\n",
      "          Linear-109               [-1, 15, 16]           1,040\n",
      "         Dropout-110               [-1, 15, 16]               0\n",
      "       LayerNorm-111               [-1, 15, 16]              32\n",
      "     ResidualAdd-112               [-1, 15, 16]               0\n",
      "         Flatten-113                  [-1, 240]               0\n",
      "         Dropout-114                  [-1, 240]               0\n",
      "          Linear-115                    [-1, 2]             482\n",
      "================================================================\n",
      "Total params: 24,866\n",
      "Trainable params: 24,866\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.86\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.96\n",
      "----------------------------------------------------------------\n",
      "Mon Nov  3 15:56:52 2025\n",
      "seed is 1465\n",
      "Subject 1\n",
      "(25794, 1, 1, 1000) (25794,) (2090, 1, 1, 1000) (2090,) (385, 1, 1, 1000) (385,)\n",
      "1_0 train_acc: 0.5205 train_loss: 0.001927\tval_acc: 0.592344 val_loss: 0.002613896, acc:0.605195\n",
      "1_38 train_acc: 0.7460 train_loss: 0.001044\tval_acc: 0.640670 val_loss: 0.002575817, acc:0.727273\n",
      "1_41 train_acc: 0.7465 train_loss: 0.001045\tval_acc: 0.633493 val_loss: 0.002553800, acc:0.735065\n",
      "1_52 train_acc: 0.7517 train_loss: 0.001020\tval_acc: 0.637321 val_loss: 0.002552626, acc:0.729870\n",
      "1_56 train_acc: 0.7559 train_loss: 0.001013\tval_acc: 0.639713 val_loss: 0.002493424, acc:0.735065\n",
      "1_60 train_acc: 0.7531 train_loss: 0.001009\tval_acc: 0.639713 val_loss: 0.002465576, acc:0.722078\n",
      "1_69 train_acc: 0.7733 train_loss: 0.000956\tval_acc: 0.664115 val_loss: 0.002460126, acc:0.706494\n",
      "1_71 train_acc: 0.7737 train_loss: 0.000952\tval_acc: 0.666029 val_loss: 0.002456387, acc:0.651948\n",
      "1_76 train_acc: 0.7766 train_loss: 0.000944\tval_acc: 0.662201 val_loss: 0.002414867, acc:0.620779\n",
      "1_77 train_acc: 0.7822 train_loss: 0.000925\tval_acc: 0.668421 val_loss: 0.002369688, acc:0.644156\n",
      "1_100 train_acc: 0.7964 train_loss: 0.000867\tval_acc: 0.670813 val_loss: 0.002339026, acc:0.628571\n",
      "1_102 train_acc: 0.7889 train_loss: 0.000895\tval_acc: 0.668900 val_loss: 0.002337203, acc:0.670130\n",
      "1_134 train_acc: 0.8033 train_loss: 0.000840\tval_acc: 0.672727 val_loss: 0.002306708, acc:0.690909\n",
      "1_178 train_acc: 0.8014 train_loss: 0.000853\tval_acc: 0.685167 val_loss: 0.002293373, acc:0.670130\n",
      "1_179 train_acc: 0.8041 train_loss: 0.000835\tval_acc: 0.680861 val_loss: 0.002284960, acc:0.683117\n",
      "1_234 train_acc: 0.8098 train_loss: 0.000815\tval_acc: 0.684211 val_loss: 0.002281271, acc:0.683117\n",
      "1_275 train_acc: 0.8129 train_loss: 0.000797\tval_acc: 0.676077 val_loss: 0.002280113, acc:0.667532\n",
      "1_315 train_acc: 0.8184 train_loss: 0.000772\tval_acc: 0.683732 val_loss: 0.002256784, acc:0.641558\n",
      "1_352 train_acc: 0.8129 train_loss: 0.000801\tval_acc: 0.681340 val_loss: 0.002255885, acc:0.628571\n",
      "1_372 train_acc: 0.8190 train_loss: 0.000769\tval_acc: 0.686603 val_loss: 0.002244301, acc:0.594805\n",
      "1_390 train_acc: 0.8060 train_loss: 0.000817\tval_acc: 0.694737 val_loss: 0.002238157, acc:0.631169\n",
      "1_415 train_acc: 0.8169 train_loss: 0.000780\tval_acc: 0.687560 val_loss: 0.002219251, acc:0.607792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 786\u001b[0m\n\u001b[1;32m    782\u001b[0m summary(sModel, (\u001b[38;5;241m1\u001b[39m, number_channel, \u001b[38;5;241m1000\u001b[39m)) \n\u001b[1;32m    784\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39masctime(time\u001b[38;5;241m.\u001b[39mlocaltime(time\u001b[38;5;241m.\u001b[39mtime())))\n\u001b[0;32m--> 786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRESULT_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m                \u001b[49m\u001b[43mevaluate_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEVALUATE_MODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m                \u001b[49m\u001b[43mheads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m                \u001b[49m\u001b[43memb_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMB_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEPTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m                \u001b[49m\u001b[43meeg1_f1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEGNet1_F1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                \u001b[49m\u001b[43meeg1_kernel_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEGNet1_KERNEL_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                \u001b[49m\u001b[43meeg1_D\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEGNet1_D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                \u001b[49m\u001b[43meeg1_pooling_size1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEGNet1_POOL_SIZE1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                \u001b[49m\u001b[43meeg1_pooling_size2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEGNet1_POOL_SIZE2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[43meeg1_dropout_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEEGNet1_DROPOUT_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                \u001b[49m\u001b[43mflatten_eeg1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLATTEN_EEGNet1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidate_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidate_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39masctime(time\u001b[38;5;241m.\u001b[39mlocaltime(time\u001b[38;5;241m.\u001b[39mtime())))\n",
      "Cell \u001b[0;32mIn[9], line 675\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dirs, evaluate_mode, heads, emb_size, depth, dataset_type, eeg1_f1, eeg1_kernel_size, eeg1_D, eeg1_pooling_size1, eeg1_pooling_size2, eeg1_dropout_rate, flatten_eeg1, validate_ratio, batch_size)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubject \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    658\u001b[0m exp \u001b[38;5;241m=\u001b[39m ExP(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, DATA_DIR, dirs, EPOCHS, N_AUG, N_SEG, gpus, \n\u001b[1;32m    659\u001b[0m           evaluate_mode \u001b[38;5;241m=\u001b[39m evaluate_mode,\n\u001b[1;32m    660\u001b[0m           heads\u001b[38;5;241m=\u001b[39mheads, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    672\u001b[0m           batch_size \u001b[38;5;241m=\u001b[39m batch_size \n\u001b[1;32m    673\u001b[0m           )\n\u001b[0;32m--> 675\u001b[0m testAcc, Y_true, Y_pred, df_process, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m true_cpu \u001b[38;5;241m=\u001b[39m Y_true\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    677\u001b[0m pred_cpu \u001b[38;5;241m=\u001b[39m Y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 564\u001b[0m, in \u001b[0;36mExP.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m epoch_process[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_loss\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# validate model\u001b[39;00m\n\u001b[1;32m    561\u001b[0m (validate_loss, \n\u001b[1;32m    562\u001b[0m  validate_acc, \n\u001b[1;32m    563\u001b[0m  y_list, \n\u001b[0;32m--> 564\u001b[0m  y_pred_list) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m epoch_process[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m validate_acc                \n\u001b[1;32m    566\u001b[0m epoch_process[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m validate_loss\n",
      "Cell \u001b[0;32mIn[9], line 472\u001b[0m, in \u001b[0;36mExP.fit_test\u001b[0;34m(self, model, loss_fn, testloader)\u001b[0m\n\u001b[1;32m    469\u001b[0m x \u001b[38;5;241m=\u001b[39m Variable(x\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTensor))\n\u001b[1;32m    470\u001b[0m y \u001b[38;5;241m=\u001b[39m Variable(y\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLongTensor))\n\u001b[0;32m--> 472\u001b[0m features, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m    474\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 270\u001b[0m, in \u001b[0;36mEEGTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m cnn \u001b[38;5;241m=\u001b[39m cnn \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_size)\n\u001b[1;32m    269\u001b[0m cnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition(cnn)\n\u001b[0;32m--> 270\u001b[0m trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m features \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m+\u001b[39mtrans\n\u001b[1;32m    273\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(features))\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 163\u001b[0m, in \u001b[0;36mResidualAdd.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    162\u001b[0m     x_input \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 163\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(res)\u001b[38;5;241m+\u001b[39mx_input)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 113\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    111\u001b[0m keys \u001b[38;5;241m=\u001b[39m rearrange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys(x), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb n (h d) -> b h n d\u001b[39m\u001b[38;5;124m\"\u001b[39m, h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n\u001b[1;32m    112\u001b[0m values \u001b[38;5;241m=\u001b[39m rearrange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues(x), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb n (h d) -> b h n d\u001b[39m\u001b[38;5;124m\"\u001b[39m, h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n\u001b[0;32m--> 113\u001b[0m energy \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbhqd, bhkd -> bhqk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mmin\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/torch/functional.py:373\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    375\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CTNet: A Convolution-Transformer Network for EEG-Based Motor Imagery Classification\n",
    "\n",
    "author: zhaowei701@163.com\n",
    "\n",
    "Due to memory constraints, the data augmentation method in LOSO classification was slightly optimized based on the approach used in subject-specific classification (main.py).\n",
    "\n",
    "\n",
    "Cite this work\n",
    "Zhao, W., Jiang, X., Zhang, B. et al. CTNet: a convolutional transformer network for EEG-based motor imagery classification. Sci Rep 14, 20237 (2024). https://doi.org/10.1038/s41598-024-71118-7\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "gpus = [0]\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "from pandas import ExcelWriter\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from utils import calMetrics\n",
    "from utils import calculatePerClass\n",
    "from utils import numberClassChannel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from einops import rearrange, reduce, repeat\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import numberClassChannel\n",
    "from utils import load_data_evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score  \n",
    "from sklearn.metrics import f1_score  \n",
    "\n",
    "\n",
    "\n",
    "class PatchEmbeddingCNN(nn.Module):\n",
    "    def __init__(self, f1=16, kernel_size=64, D=2, pooling_size1=8, pooling_size2=8, dropout_rate=0.3, number_channel=22, emb_size=40):\n",
    "        super().__init__()\n",
    "        f2 = D*f1\n",
    "        self.cnn_module = nn.Sequential(\n",
    "            # temporal conv kernel size 64=0.25fs\n",
    "            nn.Conv2d(1, f1, (1, kernel_size), (1, 1), padding='same', bias=False), # [batch, 22, 1000] \n",
    "            nn.BatchNorm2d(f1),\n",
    "            # channel depth-wise conv\n",
    "            nn.Conv2d(f1, f2, (number_channel, 1), (1, 1), groups=f1, padding='valid', bias=False), # \n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            # average pooling 1\n",
    "            nn.AvgPool2d((1, pooling_size1)),  # pooling acts as slicing to obtain 'patch' along the time dimension as in ViT\n",
    "            nn.Dropout(dropout_rate),\n",
    "            # spatial conv\n",
    "            nn.Conv2d(f2, f2, (1, 16), padding='same', bias=False), \n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "\n",
    "            # average pooling 2 to adjust the length of feature into transformer encoder\n",
    "            nn.AvgPool2d((1, pooling_size2)),\n",
    "            nn.Dropout(dropout_rate),  \n",
    "                    \n",
    "        )\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        b, _, _, _ = x.shape\n",
    "        x = self.cnn_module(x)\n",
    "        x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_heads = num_heads\n",
    "        self.keys = nn.Linear(emb_size, emb_size)\n",
    "        self.queries = nn.Linear(emb_size, emb_size)\n",
    "        self.values = nn.Linear(emb_size, emb_size)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.projection = nn.Linear(emb_size, emb_size)\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
    "        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "        values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)  \n",
    "        if mask is not None:\n",
    "            fill_value = torch.finfo(torch.float32).min\n",
    "            energy.mask_fill(~mask, fill_value)\n",
    "\n",
    "        scaling = self.emb_size ** (1 / 2)\n",
    "        att = F.softmax(energy / scaling, dim=-1)\n",
    "        att = self.att_drop(att)\n",
    "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
    "        out = self.projection(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "# PointWise FFN\n",
    "class FeedForwardBlock(nn.Sequential):\n",
    "    def __init__(self, emb_size, expansion, drop_p):\n",
    "        super().__init__(\n",
    "            nn.Linear(emb_size, expansion * emb_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(expansion * emb_size, emb_size),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Sequential):\n",
    "    def __init__(self, flatten_number, n_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(flatten_number, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, fn, emb_size, drop_p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.drop = nn.Dropout(drop_p)\n",
    "        self.layernorm = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        x_input = x\n",
    "        res = self.fn(x, **kwargs)\n",
    "        \n",
    "        out = self.layernorm(self.drop(res)+x_input)\n",
    "        return out\n",
    "\n",
    "class TransformerEncoderBlock(nn.Sequential):\n",
    "    def __init__(self,\n",
    "                 emb_size,\n",
    "                 num_heads=4,\n",
    "                 drop_p=0.5,\n",
    "                 forward_expansion=4,\n",
    "                 forward_drop_p=0.5):\n",
    "        super().__init__(\n",
    "            ResidualAdd(nn.Sequential(\n",
    "                MultiHeadAttention(emb_size, num_heads, drop_p),\n",
    "                ), emb_size, drop_p),\n",
    "            ResidualAdd(nn.Sequential(\n",
    "                FeedForwardBlock(emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
    "                ), emb_size, drop_p)\n",
    "            \n",
    "            )    \n",
    "        \n",
    "        \n",
    "class TransformerEncoder(nn.Sequential):\n",
    "    def __init__(self, heads, depth, emb_size):\n",
    "        super().__init__(*[TransformerEncoderBlock(emb_size, heads) for _ in range(depth)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BranchEEGNetTransformer(nn.Sequential):\n",
    "    def __init__(self, heads=4, \n",
    "                 depth=6, \n",
    "                 emb_size=40, \n",
    "                 number_channel=22,\n",
    "                 f1 = 20,\n",
    "                 kernel_size = 64,\n",
    "                 D = 2,\n",
    "                 pooling_size1 = 8,\n",
    "                 pooling_size2 = 8,\n",
    "                 dropout_rate = 0.3,\n",
    "                 **kwargs):\n",
    "        super().__init__(\n",
    "            PatchEmbeddingCNN(f1=f1, \n",
    "                                 kernel_size=kernel_size,\n",
    "                                 D=D, \n",
    "                                 pooling_size1=pooling_size1, \n",
    "                                 pooling_size2=pooling_size2, \n",
    "                                 dropout_rate=dropout_rate,\n",
    "                                 number_channel=number_channel,\n",
    "                                 emb_size=emb_size),\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "class PositioinalEncoding(nn.Module):\n",
    "    def __init__(self, embedding, length=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.encoding = nn.Parameter(torch.randn(1, length, embedding))\n",
    "    def forward(self, x): # x-> [batch, embedding, length]\n",
    "        x = x + self.encoding[:, :x.shape[1], :].cuda()\n",
    "        return self.dropout(x)        \n",
    "        \n",
    "   \n",
    "    \n",
    "class EEGTransformer(nn.Module):\n",
    "    def __init__(self, heads=4, \n",
    "                 emb_size=40,\n",
    "                 depth=6, \n",
    "                 database_type='A', \n",
    "                 eeg1_f1 = 20,\n",
    "                 eeg1_kernel_size = 64,\n",
    "                 eeg1_D = 2,\n",
    "                 eeg1_pooling_size1 = 8,\n",
    "                 eeg1_pooling_size2 = 8,\n",
    "                 eeg1_dropout_rate = 0.3,\n",
    "                 eeg1_number_channel = 22,\n",
    "                 flatten_eeg1 = 600,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.number_class, self.number_channel = numberClassChannel(database_type)\n",
    "        self.emb_size = emb_size\n",
    "        self.flatten_eeg1 = flatten_eeg1\n",
    "        self.flatten = nn.Flatten()\n",
    "        # print('self.number_channel', self.number_channel)\n",
    "        self.cnn = BranchEEGNetTransformer(heads, depth, emb_size, number_channel=self.number_channel,\n",
    "                                              f1 = eeg1_f1,\n",
    "                                              kernel_size = eeg1_kernel_size,\n",
    "                                              D = eeg1_D,\n",
    "                                              pooling_size1 = eeg1_pooling_size1,\n",
    "                                              pooling_size2 = eeg1_pooling_size2,\n",
    "                                              dropout_rate = eeg1_dropout_rate,\n",
    "                                              )\n",
    "        self.position = PositioinalEncoding(emb_size, dropout=0.1)\n",
    "        self.trans = TransformerEncoder(heads, depth, emb_size)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classification = ClassificationHead(self.flatten_eeg1 , self.number_class) # FLATTEN_EEGNet + FLATTEN_cnn_module\n",
    "    def forward(self, x):\n",
    "        cnn = self.cnn(x)\n",
    "        cnn = cnn * math.sqrt(self.emb_size)\n",
    "        cnn = self.position(cnn)\n",
    "        trans = self.trans(cnn)\n",
    "        \n",
    "        features = cnn+trans\n",
    "        out = self.classification(self.flatten(features))\n",
    "        return features, out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ExP():\n",
    "    def __init__(self, nsub, data_dir, result_name, \n",
    "                 epochs=2000, \n",
    "                 number_aug=2,\n",
    "                 number_seg=8, \n",
    "                 gpus=[0], \n",
    "                 evaluate_mode = 'subject-dependent',\n",
    "                 heads=4, \n",
    "                 emb_size=40,\n",
    "                 depth=6, \n",
    "                 dataset_type='A',\n",
    "                 eeg1_f1 = 20,\n",
    "                 eeg1_kernel_size = 64,\n",
    "                 eeg1_D = 2,\n",
    "                 eeg1_pooling_size1 = 8,\n",
    "                 eeg1_pooling_size2 = 8,\n",
    "                 eeg1_dropout_rate = 0.3,\n",
    "                 flatten_eeg1 = 600, \n",
    "                 validate_ratio = 0.2,\n",
    "                 learning_rate = 0.001,\n",
    "                 batch_size = 72,  \n",
    "                 ):\n",
    "        \n",
    "        super(ExP, self).__init__()\n",
    "        self.dataset_type = dataset_type\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = learning_rate\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.n_epochs = epochs\n",
    "        self.nSub = nsub\n",
    "        self.number_augmentation = number_aug\n",
    "        self.number_seg = number_seg\n",
    "        self.root = data_dir\n",
    "        self.heads=heads\n",
    "        self.emb_size=emb_size\n",
    "        self.depth=depth\n",
    "        self.result_name = result_name\n",
    "        self.evaluate_mode = evaluate_mode\n",
    "        self.validate_ratio = validate_ratio\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.number_class, self.number_channel = numberClassChannel(self.dataset_type)\n",
    "        self.model = EEGTransformer(\n",
    "             heads=self.heads, \n",
    "             emb_size=self.emb_size,\n",
    "             depth=self.depth, \n",
    "            database_type=self.dataset_type, \n",
    "            eeg1_f1=eeg1_f1, \n",
    "            eeg1_D=eeg1_D,\n",
    "            eeg1_kernel_size=eeg1_kernel_size,\n",
    "            eeg1_pooling_size1 = eeg1_pooling_size1,\n",
    "            eeg1_pooling_size2 = eeg1_pooling_size2,\n",
    "            eeg1_dropout_rate = eeg1_dropout_rate,\n",
    "            eeg1_number_channel = self.number_channel,\n",
    "            flatten_eeg1 = flatten_eeg1,  \n",
    "            ).cuda()\n",
    "        #self.model = nn.DataParallel(self.model, device_ids=gpus)\n",
    "        self.model = self.model.cuda()\n",
    "        self.model_filename = self.result_name + '/model_{}.pth'.format(self.nSub)\n",
    "        \n",
    "\n",
    "\n",
    "    # Segmentation and Reconstruction (S&R) data augmentation\n",
    "    def interaug(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        \n",
    "        number_segmentation_points = 1000 // self.number_seg\n",
    "        for clsAug in range(self.number_class):\n",
    "            cls_idx = np.where(label == clsAug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            number_records_by_augmentation = self.number_augmentation * tmp_data.shape[0]\n",
    "            tmp_aug_data = np.zeros((number_records_by_augmentation, 1, self.number_channel, 1000))\n",
    "            for ri in range(number_records_by_augmentation):\n",
    "                for rj in range(self.number_seg):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], self.number_seg)\n",
    "                    tmp_aug_data[ri, :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points] = \\\n",
    "                        tmp_data[rand_idx[rj], :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points]\n",
    "\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append([clsAug + 1]*number_records_by_augmentation)\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        # aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        # aug_data = aug_data[aug_shuffle, :, :]\n",
    "        # aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        # aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        # aug_data = aug_data.float()\n",
    "        # aug_label = torch.from_numpy(aug_label-1).cuda()\n",
    "        # aug_label = aug_label.long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "\n",
    "\n",
    "    def get_source_data(self):\n",
    "        (self.train_data,    # (batch, channel, length)\n",
    "         self.train_label, \n",
    "         self.test_data, \n",
    "         self.test_label) = load_data_evaluate(self.root, self.dataset_type, self.nSub, mode_evaluate=self.evaluate_mode)\n",
    "\n",
    "        self.train_data = np.expand_dims(self.train_data, axis=1)  # (288, 1, 22, 1000)\n",
    "        self.train_label = np.transpose(self.train_label) \n",
    "        \n",
    "        self.allData = self.train_data\n",
    "        self.allLabel = self.train_label[0]  \n",
    "        # split original allData into training and validate datasets\n",
    "\n",
    "        train_data_list = []\n",
    "        train_label_list = []\n",
    "        validate_data_list = []\n",
    "        validate_label_list = []\n",
    "        for cls in range(self.number_class):\n",
    "            # filter by class \n",
    "            cls_idx = np.where(self.allLabel == cls + 1)\n",
    "            cat_data = self.allData[cls_idx]\n",
    "            cat_label = self.allLabel[cls_idx]\n",
    "\n",
    "            \n",
    "            # each category split\n",
    "            number_sample = cat_data.shape[0]\n",
    "            number_validate = int(self.validate_ratio * number_sample)\n",
    "            # shuffle index\n",
    "            index_shuffle = np.random.permutation(len(cat_data))\n",
    "            index_train = index_shuffle[:-number_validate]\n",
    "            index_validate = index_shuffle[-number_validate:]\n",
    "            \n",
    "            train_data_list.append(cat_data[index_train])\n",
    "            train_label_list.append(cat_label[index_train])\n",
    "            \n",
    "            validate_data_list.append(cat_data[index_validate])\n",
    "            validate_label_list.append(cat_label[index_validate])\n",
    "        \n",
    "        # data augmentation\n",
    "        aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "            \n",
    "        train_data_list.append(aug_data)\n",
    "        train_label_list.append(aug_label)\n",
    "            \n",
    "        self.trainData = np.concatenate(train_data_list)\n",
    "        self.trainLabel = np.concatenate(train_label_list)\n",
    "        self.validateData = np.concatenate(validate_data_list)\n",
    "        self.validateLabel = np.concatenate(validate_label_list)\n",
    "        \n",
    "        # shuffle in all category\n",
    "        shuffle_num = np.random.permutation(len(self.trainData))\n",
    "        self.trainData = self.trainData[shuffle_num, :, :, :]  # (number of training sample, 1, 22, 1000)\n",
    "        self.trainLabel = self.trainLabel[shuffle_num]\n",
    "\n",
    "        # self.test_data = np.transpose(self.test_data, (2, 1, 0))\n",
    "        self.test_data = np.expand_dims(self.test_data, axis=1)\n",
    "        self.test_label = np.transpose(self.test_label)\n",
    "\n",
    "        self.testData = self.test_data\n",
    "        self.testLabel = self.test_label[0]\n",
    "\n",
    "        # standardize\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        # self.allData = (self.allData - target_mean) / target_std\n",
    "        self.trainData = (self.trainData - target_mean) / target_std\n",
    "        self.validateData = (self.validateData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        \n",
    "        isSaveDataLabel = False #True\n",
    "        if isSaveDataLabel:\n",
    "            np.save(\"./gradm_data/train_data_{}.npy\".format(self.nSub), self.allData)\n",
    "            np.save(\"./gradm_data/train_lable_{}.npy\".format(self.nSub), self.allLabel)\n",
    "            np.save(\"./gradm_data/test_data_{}.npy\".format(self.nSub), self.testData)\n",
    "            np.save(\"./gradm_data/test_label_{}.npy\".format(self.nSub), self.testLabel)\n",
    "        print(self.trainData.shape, self.trainLabel.shape, self.validateData.shape, self.validateLabel.shape, self.testData.shape, self.testLabel.shape)\n",
    "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "        return self.trainData, self.trainLabel, self.validateData, self.validateLabel, self.testData, self.testLabel\n",
    "\n",
    "\n",
    "\n",
    "    def fit_test(self, model, loss_fn, testloader):\n",
    "        y_list = []\n",
    "        y_pred_list = []\n",
    "\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        test_running_loss = 0\n",
    "        model.eval()  \n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = Variable(x.type(self.Tensor))\n",
    "                y = Variable(y.type(self.LongTensor))\n",
    "                \n",
    "                features, y_pred = model(x)\n",
    "                loss = loss_fn(y_pred, y)\n",
    "                y_pred = torch.argmax(y_pred, dim=1)\n",
    "                test_correct += (y_pred == y).sum().item()\n",
    "                test_total += y.size(0)\n",
    "                test_running_loss += loss.item()\n",
    "                y_pred = y_pred.cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "                y_list.extend(y)  \n",
    "                y_pred_list.extend(y_pred)  \n",
    "\n",
    "        acc_score = accuracy_score(y_list, y_pred_list)\n",
    "        epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
    "\n",
    "        return epoch_test_loss, acc_score, y_list, y_pred_list\n",
    "    \n",
    "    \n",
    "    def fit_train(self, model, loss_fn, dataloader, optimizer, trainData, trainLabel):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for train_data, train_label in dataloader:\n",
    "            # real train dataset\n",
    "            img = Variable(train_data.type(self.Tensor))\n",
    "            label = Variable(train_label.type(self.LongTensor))\n",
    "\n",
    "\n",
    "            # training model\n",
    "            features, y_pred = model(img)\n",
    "            # print(\"train outputs: \", outputs.shape, type(outputs))\n",
    "            # print(features.size())\n",
    "            loss = loss_fn(y_pred, label) \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                y_pred = torch.argmax(y_pred, dim=1)\n",
    "                correct += (y_pred == label).sum().item()\n",
    "                total += label.size(0)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(dataloader.dataset)\n",
    "        epoch_train_acc = correct / total\n",
    "\n",
    "        return epoch_train_loss, epoch_train_acc\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        img, label, validate_data, validate_label, test_data, test_label = self.get_source_data()\n",
    "        # train dataset\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        # validate dataset\n",
    "        validate_data = torch.from_numpy(validate_data)\n",
    "        validate_label = torch.from_numpy(validate_label - 1)\n",
    "        validate_dataset = torch.utils.data.TensorDataset(validate_data, validate_label)\n",
    "\n",
    "        self.validate_dataloader = torch.utils.data.DataLoader(dataset=validate_dataset, batch_size=288, shuffle=False)\n",
    "        # test dataset\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=288, shuffle=False)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        best_epoch = 0\n",
    "        num = 0\n",
    "        min_loss = 100\n",
    "        # recording train_acc, train_loss, test_acc, test_loss\n",
    "        result_process = []\n",
    "        # Train the CTNet model\n",
    "        for e in range(self.n_epochs):\n",
    "            epoch_process = {}\n",
    "            epoch_process['epoch'] = e\n",
    "            # train model\n",
    "            self.model.train()\n",
    "            train_loss, train_acc = self.fit_train(self.model, self.criterion_cls, self.dataloader, self.optimizer, self.allData, self.allLabel)\n",
    "            epoch_process['train_acc'] = train_acc\n",
    "            epoch_process['train_loss'] = train_loss\n",
    "            \n",
    "            # validate model\n",
    "            (validate_loss, \n",
    "             validate_acc, \n",
    "             y_list, \n",
    "             y_pred_list) = self.fit_test(self.model, self.criterion_cls, self.validate_dataloader)\n",
    "            epoch_process['val_acc'] = validate_acc                \n",
    "            epoch_process['val_loss'] = validate_loss\n",
    "\n",
    "#             train_pred = torch.max(outputs, 1)[1]\n",
    "#             train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
    "            num = num + 1\n",
    "\n",
    "            if min_loss>validate_loss:\n",
    "                min_loss = validate_loss\n",
    "                best_epoch = e\n",
    "                epoch_process['epoch'] = e\n",
    "                torch.save(self.model, self.model_filename)\n",
    "\n",
    "                (test_loss, \n",
    "                 test_acc, \n",
    "                 y_list, \n",
    "                 y_pred_list) = self.fit_test(self.model, self.criterion_cls, self.test_dataloader)\n",
    "                epoch_process['test_acc'] = test_acc                \n",
    "                epoch_process['test_loss'] = test_loss\n",
    "                print(\"{}_{} train_acc: {:.4f} train_loss: {:.6f}\\tval_acc: {:.6f} val_loss: {:.9f}, acc:{:.6f}\".format(self.nSub,\n",
    "                                                                                       epoch_process['epoch'],\n",
    "                                                                                       epoch_process['train_acc'],\n",
    "                                                                                       epoch_process['train_loss'],\n",
    "                                                                                       epoch_process['val_acc'],\n",
    "                                                                                       epoch_process['val_loss'],\n",
    "                                                                                       epoch_process['test_acc']\n",
    "                                                                                    ))\n",
    "            \n",
    "                \n",
    "            result_process.append(epoch_process)  \n",
    "        \n",
    "        # load model for test\n",
    "        self.model.eval()\n",
    "        self.model = torch.load(self.model_filename).cuda()\n",
    "        # test model\n",
    "        (test_loss, \n",
    "         test_acc, \n",
    "         y_list, \n",
    "         y_pred_list) = self.fit_test(self.model, self.criterion_cls, self.test_dataloader)\n",
    "\n",
    "        print(\"epoch: \", best_epoch, '\\tThe test accuracy is:', test_acc)\n",
    "\n",
    "\n",
    "        df_process = pd.DataFrame(result_process)\n",
    "\n",
    "        return test_acc, torch.tensor(y_list), torch.tensor(y_pred_list), df_process, best_epoch\n",
    "        # writer.close()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def main(dirs,                \n",
    "         evaluate_mode = 'subject-dependent', # LOSO or not\n",
    "         heads=8,             # heads of MHA\n",
    "         emb_size=48,         # token embding dim\n",
    "         depth=3,             # Transformer encoder depth\n",
    "         dataset_type='A',    # A->'BCI IV2a', B->'BCI IV2b'\n",
    "         eeg1_f1=20,          # features of temporal conv\n",
    "         eeg1_kernel_size=64, # kernel size of temporal conv\n",
    "         eeg1_D=2,            # depth-wise conv \n",
    "         eeg1_pooling_size1=8,# p1\n",
    "         eeg1_pooling_size2=8,# p2\n",
    "         eeg1_dropout_rate=0.3,\n",
    "         flatten_eeg1=600,   \n",
    "         validate_ratio = 0.2,\n",
    "         batch_size = 72\n",
    "         ):\n",
    "\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "    result_write_metric = ExcelWriter(dirs+\"/result_metric.xlsx\")\n",
    "    \n",
    "    result_metric_dict = {}\n",
    "    y_true_pred_dict = { }\n",
    "\n",
    "    process_write = ExcelWriter(dirs+\"/process_train.xlsx\")\n",
    "    pred_true_write = ExcelWriter(dirs+\"/pred_true.xlsx\")\n",
    "    subjects_result = []\n",
    "    best_epochs = []\n",
    "    \n",
    "    for i in range(0, N_SUBJECT):      \n",
    "        \n",
    "        starttime = datetime.datetime.now()\n",
    "        seed_n = np.random.randint(2024)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "        index_round =0\n",
    "        print('Subject %d' % (i+1))\n",
    "        exp = ExP(i + 1, DATA_DIR, dirs, EPOCHS, N_AUG, N_SEG, gpus, \n",
    "                  evaluate_mode = evaluate_mode,\n",
    "                  heads=heads, \n",
    "                  emb_size=emb_size,\n",
    "                  depth=depth, \n",
    "                  dataset_type=dataset_type,\n",
    "                  eeg1_f1 = eeg1_f1,\n",
    "                  eeg1_kernel_size = eeg1_kernel_size,\n",
    "                  eeg1_D = eeg1_D,\n",
    "                  eeg1_pooling_size1 = eeg1_pooling_size1,\n",
    "                  eeg1_pooling_size2 = eeg1_pooling_size2,\n",
    "                  eeg1_dropout_rate = eeg1_dropout_rate,\n",
    "                  flatten_eeg1 = flatten_eeg1,  \n",
    "                  validate_ratio = validate_ratio,\n",
    "                  batch_size = batch_size \n",
    "                  )\n",
    "\n",
    "        testAcc, Y_true, Y_pred, df_process, best_epoch = exp.train()\n",
    "        true_cpu = Y_true.cpu().numpy().astype(int)\n",
    "        pred_cpu = Y_pred.cpu().numpy().astype(int)\n",
    "        df_pred_true = pd.DataFrame({'pred': pred_cpu, 'true': true_cpu})\n",
    "        df_pred_true.to_excel(pred_true_write, sheet_name=str(i+1))\n",
    "        y_true_pred_dict[i] = df_pred_true\n",
    "\n",
    "        accuracy, precison, recall, f1, kappa = calMetrics(true_cpu, pred_cpu)\n",
    "        subject_result = {'accuray': accuracy*100,\n",
    "                          'precision': precison*100,\n",
    "                          'recall': recall*100,\n",
    "                          'f1': f1*100, \n",
    "                          'kappa': kappa*100\n",
    "                          }\n",
    "        subjects_result.append(subject_result)\n",
    "        df_process.to_excel(process_write, sheet_name=str(i+1))\n",
    "        best_epochs.append(best_epoch)\n",
    "    \n",
    "        print(' THE BEST ACCURACY IS ' + str(testAcc) + \"\\tkappa is \" + str(kappa) )\n",
    "    \n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
    "\n",
    "        if i == 0:\n",
    "            yt = Y_true\n",
    "            yp = Y_pred\n",
    "        else:\n",
    "            yt = torch.cat((yt, Y_true))\n",
    "            yp = torch.cat((yp, Y_pred))\n",
    "                \n",
    "        df_result = pd.DataFrame(subjects_result)\n",
    "    process_write.close()\n",
    "    pred_true_write.close()\n",
    "\n",
    "\n",
    "    print('**The average Best accuracy is: ' + str(df_result['accuray'].mean()) + \"kappa is: \" + str(df_result['kappa'].mean()) + \"\\n\" )\n",
    "    print(\"best epochs: \", best_epochs)\n",
    "    #df_result.to_excel(result_write_metric, index=False)\n",
    "    result_metric_dict = df_result\n",
    "\n",
    "    mean = df_result.mean(axis=0)\n",
    "    mean.name = 'mean'\n",
    "    std = df_result.std(axis=0)\n",
    "    std.name = 'std'\n",
    "    df_result = pd.concat([df_result, pd.DataFrame(mean).T, pd.DataFrame(std).T])\n",
    "    \n",
    "    df_result.to_excel(result_write_metric, index=False)\n",
    "    print('-'*9, ' all result ', '-'*9)\n",
    "    print(df_result)\n",
    "    \n",
    "    print(\"*\"*40)\n",
    "\n",
    "    result_write_metric.close()\n",
    "\n",
    "    \n",
    "    return result_metric_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #----------------------------------------\n",
    "    # vs\n",
    "    DATA_DIR = r'./bci_dataset_113-2/'  # txt\n",
    "    EVALUATE_MODE = 'LOSO' # leaving one subject out subject-dependent  subject-indenpedent\n",
    "\n",
    "    N_SUBJECT = 18       # 18 (S01-S18)\n",
    "    N_AUG = 3           # data augmentation times for benerating artificial training data set\n",
    "    N_SEG = 8           # segmentation times for S&R\n",
    "\n",
    "    EPOCHS = 600\n",
    "    EMB_DIM = 16\n",
    "    HEADS = 2\n",
    "    DEPTH = 6\n",
    "    TYPE = 'C'          # 'C' 21\n",
    "    validate_ratio = 0.3 # split raw train dataset into real train dataset and validate dataset\n",
    "    BATCH_SIZE = 512\n",
    "    EEGNet1_F1 = 8\n",
    "    EEGNet1_KERNEL_SIZE=64\n",
    "    EEGNet1_D=2\n",
    "    EEGNet1_POOL_SIZE1 = 8\n",
    "    EEGNet1_POOL_SIZE2 = 8\n",
    "    FLATTEN_EEGNet1 = 240  # 115 (patches) * 16 (f1*D = 8*2) = 240\n",
    "\n",
    "    if EVALUATE_MODE!='LOSO':\n",
    "        EEGNet1_DROPOUT_RATE = 0.5\n",
    "    else:\n",
    "        EEGNet1_DROPOUT_RATE = 0.25    \n",
    "\n",
    "    \n",
    "    parameters_list = [0, 1, 2]\n",
    "    for i in parameters_list:\n",
    "        number_class, number_channel = numberClassChannel(TYPE)\n",
    "        RESULT_NAME = \"Loso_{}_heads_{}_depth_{}_{}\".format(TYPE, HEADS, DEPTH, i)\n",
    "    \n",
    "        sModel = EEGTransformer(\n",
    "            heads=HEADS, \n",
    "            emb_size=EMB_DIM,\n",
    "            depth=DEPTH, \n",
    "            database_type=TYPE,\n",
    "            eeg1_f1=EEGNet1_F1, \n",
    "            eeg1_D=EEGNet1_D,\n",
    "            eeg1_kernel_size=EEGNet1_KERNEL_SIZE,\n",
    "            eeg1_pooling_size1 = EEGNet1_POOL_SIZE1,\n",
    "            eeg1_pooling_size2 = EEGNet1_POOL_SIZE2,\n",
    "            eeg1_dropout_rate = EEGNet1_DROPOUT_RATE,\n",
    "            eeg1_number_channel = number_channel,\n",
    "            flatten_eeg1 = FLATTEN_EEGNet1,  \n",
    "            ).cuda()\n",
    "        summary(sModel, (1, number_channel, 1000)) \n",
    "    \n",
    "        print(time.asctime(time.localtime(time.time())))\n",
    "        \n",
    "        result = main(RESULT_NAME,\n",
    "                        evaluate_mode = EVALUATE_MODE,\n",
    "                        heads=HEADS, \n",
    "                        emb_size=EMB_DIM,\n",
    "                        depth=DEPTH, \n",
    "                        dataset_type=TYPE,\n",
    "                        eeg1_f1 = EEGNet1_F1,\n",
    "                        eeg1_kernel_size = EEGNet1_KERNEL_SIZE,\n",
    "                        eeg1_D = EEGNet1_D,\n",
    "                        eeg1_pooling_size1 = EEGNet1_POOL_SIZE1,\n",
    "                        eeg1_pooling_size2 = EEGNet1_POOL_SIZE2,\n",
    "                        eeg1_dropout_rate = EEGNet1_DROPOUT_RATE,\n",
    "                        flatten_eeg1 = FLATTEN_EEGNet1,\n",
    "                        validate_ratio = validate_ratio,\n",
    "                        batch_size = BATCH_SIZE\n",
    "                      )\n",
    "        print(time.asctime(time.localtime(time.time())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
